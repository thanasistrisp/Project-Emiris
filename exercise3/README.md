# Software Development for Algorithmic Problems - Winter Semester 2023-24

# Project 3 - Dimensionality reduction via Neural Network and experimental study

Eleftheria Vrachoriti - 1115202000026

Athanasios Trispiotis - 1115202000194

# Table of Contents
- [1. Project structure](#1-project-structure)
- [2. Compilation](#2-compilation)
	- [2.1. Shared library `shared_lib.so`](#21-shared-library-shared_libso)
	- [2.2. Clean](#22-clean)
- [3. Execution](#3-execution)
	- [3.1. Python scripts](#31-python-scripts)
		- [3.1.1. `reduce.py`](#311-reducepy)
	- [3.2. C++ binaries](#32-c-binaries)
- [4. Neural Network: Autoencoder](#4-neural-network-autoencoder)
	- [4.1. Architecture](#41-architecture)
		- [4.1.1. Dense Autoencoder](#411-dense-autoencoder)
		- [4.1.2. Convolutional Autoencoder](#412-convolutional-autoencoder)
	- [4.2. Normalization of datasets](#42-normalization-of-datasets)
- [5. Nearest Neighbor Search in Latent Space](#5-nearest-neighbor-search-in-latent-space)
	- [5.1. Implementation - Evaluation](#51-implementation---evaluation)
	- [5.2 Results](#52-results)
- [6. Clustering in Latent Space](#6-clustering-in-latent-space)
	- [6.1. Implementation - Evaluation](#61-implementation---evaluation)
	- [6.2 Results](#62-results)
- [References](#references)


# 1. Project structure

```bash
├── . (exercise3)		           # directory for source code of the third (current) assignment
│   ├── lib				           # directory for shared library
│   │   └── Makefile		           # makefile for building only the shared library
│   │
│   ├── MNIST			           # directory for MNIST binary data files (input.dat, query.dat, encoded, decoded, normalized original binary files generated by python)
│   │   ├── input.dat
│   │   └── query.dat
│   │
│   ├── models			           # directory for already trained and saved autoencoder models (best selected models)
│   │   ├── model_conv_12.keras
│   │   ├── model_conv_19.keras
│   │   ├── model_conv_46.keras
│   │   ├── model_dense_1.keras
│   │   ├── model_dense_26.keras
│   │   └── model_dense_43.keras
│   │
│   ├── python_cpp_connection	   # directory for python-cpp connection files
│   │   ├── clustering.cc		       # connector functions for calculating silhouette metric in initial and latent space
│   │   ├── config.hpp
│   │   ├── kmeans_eval.cc
│   │   ├── kmeans_eval.hpp
│   │   └── nearest_neighbor.cc		   # connector functions for calculating AAF metrics (two versions)
│   │
│   ├── PDFs			           # directory containing the generated PDFs from the jupyter notebooks using nbconvert
│   │
│   ├── autoencoder.py		       # definition of the autoencoder class (Keras model)
│   ├── best_model_analysis.ipynb
│   ├── common.mk			       # main (common) makefile
│   ├── environment.yml		       # conda environment file for installing dependencies
│   ├── grid_search_kmeans_latentnonproj_and_init.ipynb.ipynb
│   ├── grid_search_kmeans_lat_init.ipynb
│   ├── grid_search_lat_init.ipynb
│   ├── helper_funcs.py		       # helper functions for loading/saving data, normalizing, plotting, numpy handling
│   ├── optimization_initial.ipynb
│   ├── optimization_latent.ipynb
│   ├── params.py			       # python functions calling the cpp functions using ctypes (sihlouette, AAF metrics)
│   ├── README.md			       # this documentation file
│   └── reduce.py			       # python requested file for generating encoded normalized binary files
│
├── ../exercise1/		           # directory for source code of the first assignment
│   └── ...
│
└── ../exercise2/		           # directory for source code of the second assignment
	└── ...
```

# 2. Compilation

## 2.1. Shared library `shared_lib.so`

Stay in the root directory of the <code>exercise3/</code> and then run the following command:

```bash
make -C lib
```

This will build the shared library <code>shared_lib.so</code> in the <code>lib/</code> directory.

Note: For GNNs, MRNG and NSG, the construction will be done based on best parameters found in <code>exercise2/include/defines_latent_space.hpp</code> and <code>exercise2/include/defines_initial_space.hpp</code> files. By default, compilation will be done for latent space. If you want to compile for initial space, you will have to comment out the shared_lib.so_FLAGS line in the Makefile and recompile (clean and rebuild) the library.

## 2.2. Clean

To remove dependency, object, shared library and executable files, run the following command at `lib/` directory:

```bash
make clean
```

# 3. Execution

## 3.1. Python scripts

### 3.1.1. `reduce.py`

This script is used to generate the encoded normalized binary files for the MNIST dataset. It is called as follows:

```bash
python reduce.py -d <dataset> -q <queryset> -od <output_dataset_file> -oq <output_query_file> [-m <keras_model>]
```
By default, one of the best models is used for encoding. If you want to use a specific model, you can specify it with the `-m` flag from `models/` directory.

## 3.2. C++ binaries

For this exercise, there are no C++ binaries to be executed (no main is defined). Only the shared library is used through `ctypes` python library. If you want to calculate various metrics on other datasets, you will have to run the equivalent cells in the Jupyter notebooks and adjust them appropriately (e.g. change paths, parameters, run one model/dataset only bypassing hyperparameter tuning, etc.).

NOTE: For previous assignments, it is not correct to run the executables with the normalized range datasets. The `main` function is designed to only work with the original MNIST datasets (integer values in range [0,255]).

# 4. Neural Network: Autoencoder

For developing our Autoencoder model, we will use the Keras framework with TensorFlow backend.

## 4.1. Architecture

Our unsupervised learning model is composed of two parts; the encoder and the decoder. First the input ($28\times28$ pixels flattened) passes through the encoder, to produce the latent layer. The decoder, which has the similar ANN structure, then produces the output only using the compressed representation. The dimensionality of the input and output are exactly the same. The goal is to get an output identical with the input.  The latent dimension will always be less than 50 to ensure that the encodings have a much smaller dimension than initial dimension of our data. Up to 5 hidden connected layers will be used. Other hyperparameters are explained in `best_model_analysis.ipynb`, where the model is optimized based on its validation loss using random search provided by the Optuna framework. Overfitting is also handled by using early stopping and manual observation of the training and validation loss in each epoch. Epochs are set to max 50 epochs for all models.

### 4.1.1. Dense Autoencoder

We start as a stack of fully-connected neural layers (a linear operation in which every input is connected to every output by a weight followed by a non-linear activation function). As we can see from the best trials Optuna returns, no model overfits. The lowest validation loss we can yield is about 0.075. For the best models, the ReLU or GELU activation functions and NAdam or Adamax optimizers are the most suitable for the hidden layers and the sigmoid function for the output layer (classification problem). Regarding the batch size, the model exhibits a better behavior with smaller batch sizes (32, 64). Simpler models with 1-2 hidden layers are better than more complex ones. Early stopping does not happen in most of the cases as epochs are not too many and the model does not overfit. As expected, better validation loss is achieved with higher latent space dimensionality, because a higher portion of the initial information is retained.

### 4.1.2. Convolutional Autoencoder

We also tried convolutional layers for our NN (a linear operation using a subset of the weights of a dense layer). As we can see from the best trials, the lowest validation loss with latent space dimensionality less than 50 is about 0.08. In this approach, a larger number of layers (about 4) is needed for better results.
We use kernel size $3\times3$, pool size $2\times2$, stride $1\times1$ and padding $same$. Filters' size varies from 8 to 64.
For the other hyperparameters, they are similar to the dense autoencoder, except for the fact that the model performs better when the batch size is larger (128, 256). Better results are achieved with the encoded representations of $(1,1,25), (2,2,8), (1,1,18)$.

Even though the convolutional autoencoder architecture is more complex than the dense one, it does not perform better. In general, when the inputs are images, convolutional neural networks (CNNs) are considered the best architecture for encoding. This is not our case here, as MNIST dataset is not complex enough and the latent dimension is too small to be exploited to its full potential (they perform better with latent dimension ~150 with about 0.07 loss).

## 4.2. Normalization of datasets

We normalize all datasets (original data, encoded representations) for both training and testing sets and map them in interval $[0,1]$. It is necessary for the data to be in the same scale to be able to compare distances proportionally, otherwise the results will be biased. Normalization in same space does not affect the results. Normalization is done in Python and data are saved as `float32` in binary files (C++ `float` equivalent data type).

# 5. Nearest Neighbor Search in Latent Space

## 5.1. Implementation - Evaluation

To evaluate nearest neighbor search in latent space and see how the model performs in latent space, we need to project the "encoded" point (approximate neighbor to encoded query) back to initial space and compare it with the true neighbor to query in initial space. For this evaluation, we calculate the fraction:
$$
	AAF_{average\_over\_all\_queries} = \frac{p_{approximate\_neighbor_{projected}} - q_{initial}}{p_{{true\_nearest\_neighbor}_{initial}} - q_{initial}}
$$

For finding the approximate nearest neighbor in latent space, we need to re-evaluate the hyperparameters for each algorithm as the previous hyperparameters do not perform well in significantly lower dimension space. We also calculate the true nearest neighbors in latent space for evaluation purposes.

To apply nearest neighbor (nn) search in latent space, we need to encode whole dataset and query sets using the `encode()` function of the autoencoder model. Then, the encodings are saved to binary files as `float32` in interval $[0,1]$ and loaded back to C++. We can project nearest neighbor encoded back to initial space just by using its index in the initial dataset, as the datasets are not shuffled.

## 5.2 Results

Analysis is done in 3 notebooks:

- `optimization_initial.ipynb`: recalculate the best hyparameters, AAF and average query time for each non-clustering algorithm (LSH, Hypercube, GNNS, MRNG, NSG) in the initial space using the AAF (Average Approximation Factor) instead of the MAF (Maximum Approximation Factor) metric.
- `optimization_latent.ipynb`: calculate the best hyparameters, AAF and average query time for each non-clustering algorithm (LSH, Hypercube, GNNS, MRNG, NSG) only in the latent space. AAF evaluation in this case is only used for hyperparameter tuning, because the points are not projected back to initial space.
- `grid_search_lat_init.ipynb`: using the best hyperparameters for the latent space, for each of the 6 best autoencoder models and for each algorithm (Brute-force, LSH, Hypercube, GNNS, MRNG, NSG) we evaluate the AAF between initial and latent space and the time needed for the search in latent space.

# 6. Clustering in Latent Space

## 6.1. Implementation - Evaluation

For clustering in latent space, we use the same approach as in nearest neighbor search in latent space. We encode the whole dataset and query sets using the `encode()` function of the autoencoder model. Then, the encodings are saved to binary files as `float32` in interval $[0,1]$ and loaded back to C++. All points inside clusters can be projected back to initial space just by using their index in the initial dataset. However, this is not the case for the centroids of the clusters as it is not guaranteed that they belong to the dataset. For this reason, we need to use the `decode()` function of the model to project them back to initial space where they can also not belong to the initial dataset. The decoding process is done in memory using `ctypes`.

For the evaluation, we use both the silhouette metric and the objective function value, defined as:

$$
	J = \sum_{i=1}^{k} \sum_{x \in S_i} \left\| x - c_i \right\|^2
$$

where:

$k$: the number of clusters

$S_i$: the $i$-th cluster

$c_i$: the centroid of the $i$-th cluster

The value of the objective function gives a local minimum for the clustering problem generated from the K-Means algorithm.

## 6.2 Results

Analysis is done in 2 notebooks:

- `grid_search_kmeans_latentnonproj_and_init.ipynb`: using the best hyperparameters for the LSH and Hypercube algorithms in both latent and initial space, we measure the difference in clustering time and metrics. In this case, comparing the metrics does not make sense as we calculate them without using projection to initial space, but they are indicative of the general performance of the algorithms in lower dimensions.
- `grid_search_kmeans_lat_init.ipynb`: using the best hyperparameters for the LSH and Hypercube algorithms in latent space, for each of the 6 best autoencoder models and for each K-Means variation (Classic using Lloyd's method, Reverse LSH, Reverse Hypercube) we evaluate the silhouette metric between initial and latent space and the objective function value.

# References

[1] LeCun, Y., Cortes, C., & Burges, C.. THE MNIST DATABASE
of handwritten digits. https://yann.lecun.com/exdb/mnist/

[2] K-Means clustering - Wikipedia
https://en.wikipedia.org/wiki/K-means_clustering

[3] Building Autoencoders in Keras
https://blog.keras.io/building-autoencoders-in-keras.html

[4] Keras: The high-level API for TensorFlow
https://www.tensorflow.org/guide/keras

[5] ctypes - A foreign function library for Python
https://docs.python.org/3/library/ctypes.html

[6] Optuna - A hyperparameter optimization framework
https://optuna.org/
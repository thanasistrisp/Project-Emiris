{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optimization_initial notebook cells to be copied to original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_pareto_front, plot_optimization_history, plot_slice\n",
    "\n",
    "from params import lsh_test, hypercube_test, gnn_test, mrng_test, nsg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = b'MNIST/input.dat'\n",
    "query_path = b'MNIST/query.dat'\n",
    "\n",
    "n = 60000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gnns(trial):\n",
    "    param_dict = {'k': trial.suggest_int('k', 40, 100)}\n",
    "    param_dict.update({'E': trial.suggest_int('E', 40, param_dict['k'])})\n",
    "    param_dict.update({'R': trial.suggest_int('R', 1, 10)})\n",
    "\n",
    "    print(\"Trial params\", param_dict)\n",
    "\n",
    "    average_time, aaf = gnn_test(input_path, query_path, queries_num=100, **param_dict, N=5)\n",
    "\n",
    "    return aaf.value, average_time.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gnns_study = optuna.create_study(study_name='gnns', directions=['minimize', 'minimize'])\n",
    "gnns_study.optimize(objective_gnns, n_trials=50, n_jobs=-1)\n",
    "print(\"-------------------- Best trials --------------------\")\n",
    "trials = sorted(gnns_study.best_trials, key=lambda x: x.values)\n",
    "for trial in trials:\n",
    "    print(\"Trial no. {}\".format(trial.number))\n",
    "    print(\" Values = {}\".format(trial.values))\n",
    "    print(\" Params = {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gnns_study.trials_dataframe()\n",
    "\n",
    "df_sorted = df.copy(deep=True)\n",
    "df_sorted = df_sorted.dropna(subset=['values_0', 'values_1'])\n",
    "df_sorted = df_sorted.sort_values(by=['values_0', 'values_1'], ascending=[True, True])\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(gnns_study, target_names=['aaf', 'average_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(gnns_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(gnns_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(gnns_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(gnns_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = b'../exercise2/graph_files/mrng_graph_aaf.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mrng(trial):\n",
    "    param_dict = {'l': trial.suggest_int('l', 1, 1000)}\n",
    "    \n",
    "    print(\"Trial parameters:\", param_dict)\n",
    "\n",
    "    average_time, aaf = mrng_test(input_path, query_path, queries_num=100, **param_dict, N=5, int_data=1, load_file=load_file)\n",
    " \n",
    "    return aaf.value, average_time.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mrng_study = optuna.create_study(study_name='mrng', directions=['minimize', 'minimize'])\n",
    "mrng_study.optimize(objective_mrng, n_trials=50, n_jobs=-1)\n",
    "print(\"-------------------- Best trials --------------------\")\n",
    "trials = sorted(mrng_study.best_trials, key=lambda x: x.values)\n",
    "for trial in trials:\n",
    "    print(\"Trial no. {}\".format(trial.number))\n",
    "    print(\" Values = {}\".format(trial.values))\n",
    "    print(\" Params = {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mrng_study.trials_dataframe()\n",
    "\n",
    "df_sorted = df.copy(deep=True)\n",
    "df_sorted = df_sorted.dropna(subset=['values_0', 'values_1'])\n",
    "df_sorted = df_sorted.sort_values(by=['values_0', 'values_1'], ascending=[True, True])\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(mrng_study, target_names=['aaf', 'average_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(mrng_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(mrng_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(mrng_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(mrng_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_nsg(trial):\n",
    "    param_dict = {'m' : trial.suggest_int('m', 3, 500),\n",
    "                  'l' : trial.suggest_int('l', 10, 4000),\n",
    "                  'lq': trial.suggest_int('lq', 1, 2000),\n",
    "                  'k' : trial.suggest_int('k', 40, 100)}\n",
    "    \n",
    "    print(\"Trial parameters:\", param_dict)\n",
    "\n",
    "    average_time, aaf = nsg_test(input_path, query_path, queries_num=100, **param_dict, N=5)\n",
    "\n",
    "    return aaf.value, average_time.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nsg_study = optuna.create_study(study_name='nsg', directions=['minimize', 'minimize'])\n",
    "nsg_study.optimize(objective_nsg, n_trials=50, n_jobs=-1)\n",
    "print(\"-------------------- Best trials --------------------\")\n",
    "trials = sorted(nsg_study.best_trials, key=lambda x: x.values)\n",
    "for trial in trials:\n",
    "    print(\"Trial no. {}\".format(trial.number))\n",
    "    print(\" Values = {}\".format(trial.values))\n",
    "    print(\" Params = {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nsg_study.trials_dataframe()\n",
    "\n",
    "df_sorted = df.copy(deep=True)\n",
    "df_sorted = df_sorted.dropna(subset=['values_0', 'values_1'])\n",
    "df_sorted = df_sorted.sort_values(by=['values_0', 'values_1'], ascending=[True, True])\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(nsg_study, target_names=['aaf', 'average_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(nsg_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(nsg_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(nsg_study, target = lambda t: t.values[0], target_name = 'aaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(nsg_study, target = lambda t: t.values[1], target_name = 'average_time')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for K-Means in Initial and Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import threading\n",
    "from threading import Lock\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from helper_funcs import *\n",
    "\n",
    "import pandas\n",
    "pandas.set_option('display.max_rows', None)\n",
    "\n",
    "from params import kmeans_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create files for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir('./models/')\n",
    "\n",
    "dataset = b'MNIST/input.dat'\n",
    "query   = b'MNIST/query.dat'\n",
    "\n",
    "model_to_files = {}\n",
    "for i, model in enumerate(models):\n",
    "    normalized_dataset = b'MNIST/' + models[i].removesuffix('.keras').encode() + b'_normalized_dataset.dat'\n",
    "    normalized_query   = b'MNIST/' + models[i].removesuffix('.keras').encode() + b'_normalized_query.dat'\n",
    "    encoded_dataset    = b'MNIST/' + models[i].removesuffix('.keras').encode() + b'_encoded_dataset.dat'\n",
    "    encoded_query      = b'MNIST/' + models[i].removesuffix('.keras').encode() + b'_encoded_query.dat'\n",
    "\n",
    "    model_to_files.update({models[i] : [normalized_dataset, normalized_query,\n",
    "                                        encoded_dataset, encoded_query]})\n",
    "\n",
    "n = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_to_files:\n",
    "    normalized_dataset, normalized_query, encoded_dataset, encoded_query = model_to_files[model]\n",
    "\n",
    "    model = b'models/' + model.encode()\n",
    "\n",
    "    # load model\n",
    "    autoencoder = load_model(model.decode())\n",
    "    shape = autoencoder.layers[-2].output_shape[1:] # get shape of encoded layer\n",
    "\n",
    "    # load dataset\n",
    "    x_train = load_dataset(dataset)\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = load_dataset(query)\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    if len(shape) == 3: # if model type is convolutional\n",
    "        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "    else:\n",
    "        x_train = np.reshape(x_train, (len(x_train), 784))\n",
    "        x_test = np.reshape(x_test, (len(x_test), 784))\n",
    "\n",
    "    encoded_train = autoencoder.encode(x_train)\n",
    "    encoded_test = autoencoder.encode(x_test)\n",
    "\n",
    "    # deflatten encoded datasets\n",
    "    encoded_train = deflatten_encoded(encoded_train, shape)\n",
    "    encoded_test = deflatten_encoded(encoded_test, shape)\n",
    "\n",
    "    # save original datasets normalized\n",
    "    save_decoded_binary(x_train, normalized_dataset)\n",
    "    save_decoded_binary(x_test, normalized_query)\n",
    "\n",
    "    # normalize encoded datasets\n",
    "    encoded_train = normalize(encoded_train)\n",
    "    encoded_test = normalize(encoded_test)\n",
    "\n",
    "    # save encoded datasets\n",
    "    save_encoded_binary(encoded_train, encoded_dataset)\n",
    "    save_encoded_binary(encoded_test, encoded_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for K-Means in Initial Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset = b'MNIST/model_conv_12_normalized_dataset.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lsh = [5, 6, 7500, 2222]          # L, k, limit_queries, window\n",
    "best_params_hypercube = [2153, 13, 950, 2222] # M, k, probes, window\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(clustering_time, stotal_latent, silhouette, obj_func):\n",
    "    print(\"Clustering time       :\", clustering_time)\n",
    "    print(\"Total silhouette      :\", stotal_latent)\n",
    "    print(\"Silhouette per cluster:\", silhouette)\n",
    "    print(\"Objective function    :\", obj_func)\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "def run_kmeans_classic_initial():\n",
    "    config = {\n",
    "        'model': b'CLASSIC',\n",
    "        'vals': [],\n",
    "        'dataset': normalized_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append(['CLASSIC', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette\n",
    "\n",
    "def run_kmeans_lsh_initial():\n",
    "    config = {\n",
    "        'model': b'LSH',\n",
    "        'vals': best_params_lsh[:-1],\n",
    "        'window': best_params_lsh[-1],\n",
    "        'dataset': normalized_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append(['LSH', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette\n",
    "\n",
    "def run_kmeans_cube_initial():\n",
    "    config = {\n",
    "        'model': b'CUBE',\n",
    "        'vals': best_params_hypercube[:-1],\n",
    "        'window': best_params_hypercube[-1],\n",
    "        'dataset': normalized_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append(['CUBE', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ThreadPool(processes=3)\n",
    "\n",
    "pool.apply_async(run_kmeans_classic_initial)\n",
    "pool.apply_async(run_kmeans_lsh_initial)\n",
    "pool.apply_async(run_kmeans_cube_initial)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_methods, col_clustering_time, col_stotal_latent, obj_func = [], [], [], []\n",
    "\n",
    "for row in rows:\n",
    "    method, clustering_time, stotal_latent, silhouette, obj = row\n",
    "\n",
    "    col_methods.append(method)\n",
    "    col_clustering_time.append(clustering_time)\n",
    "    col_stotal_latent.append(stotal_latent)\n",
    "    obj_func.append(obj)\n",
    "\n",
    "col_dict = {'method': col_methods, 'clustering time': col_clustering_time,\n",
    "            'silhouette total': col_stotal_latent, 'objective function': obj_func}\n",
    "\n",
    "df = pandas.DataFrame(data=col_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for K-Means in Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T10:21:14.455627Z",
     "iopub.status.busy": "2024-01-03T10:21:14.455297Z",
     "iopub.status.idle": "2024-01-03T10:21:14.461136Z",
     "shell.execute_reply": "2024-01-03T10:21:14.460201Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params_lsh = [4, 7, 1, 0.6]            # L, k, limit_queries, window\n",
    "best_params_hypercube = [67, 3, 1000, 0.42] # M, k, probes, window\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T10:21:14.464548Z",
     "iopub.status.busy": "2024-01-03T10:21:14.464273Z",
     "iopub.status.idle": "2024-01-03T10:21:14.474857Z",
     "shell.execute_reply": "2024-01-03T10:21:14.474226Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_results(clustering_time, stotal_latent, silhouette, obj_func):\n",
    "    print(\"Clustering time       :\", clustering_time)\n",
    "    print(\"Total silhouette      :\", stotal_latent)\n",
    "    print(\"Silhouette per cluster:\", silhouette)\n",
    "    print(\"Objective function    :\", obj_func)\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "def run_kmeans_classic_latent(model):\n",
    "    encoded_dataset = model_to_files[model][2]\n",
    "\n",
    "    config = {\n",
    "        'model': b'CLASSIC',\n",
    "        'vals': [],\n",
    "        'dataset': encoded_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append([model, 'CLASSIC', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette\n",
    "\n",
    "def run_kmeans_lsh_latent(model):\n",
    "    encoded_dataset = model_to_files[model][2]\n",
    "\n",
    "    config = {\n",
    "        'model': b'LSH',\n",
    "        'vals': best_params_lsh[:-1],\n",
    "        'window': best_params_lsh[-1],\n",
    "        'dataset': encoded_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append([model, 'LSH', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette\n",
    "\n",
    "def run_kmeans_cube_latent(model):\n",
    "    encoded_dataset = model_to_files[model][2]\n",
    "\n",
    "    config = {\n",
    "        'model': b'CUBE',\n",
    "        'vals': best_params_hypercube[:-1],\n",
    "        'window': best_params_hypercube[-1],\n",
    "        'dataset': encoded_dataset,\n",
    "    }\n",
    "\n",
    "    clustering_time, stotal_latent, silhouette, obj = kmeans_test(conf=config, int_data=0)\n",
    "\n",
    "    print_results(clustering_time.value, stotal_latent.value, silhouette.val, obj.value)\n",
    "\n",
    "    sil_val = silhouette.val\n",
    "\n",
    "    rows.append([model, 'CUBE', clustering_time.value, stotal_latent.value, sil_val, obj.value])\n",
    "\n",
    "    del silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T10:21:14.477847Z",
     "iopub.status.busy": "2024-01-03T10:21:14.477608Z",
     "iopub.status.idle": "2024-01-03T11:01:08.314596Z",
     "shell.execute_reply": "2024-01-03T11:01:08.313894Z"
    }
   },
   "outputs": [],
   "source": [
    "pool = ThreadPool(processes=4)\n",
    "\n",
    "for model in models:\n",
    "    pool.apply_async(run_kmeans_classic_latent, (model,))\n",
    "    pool.apply_async(run_kmeans_lsh_latent, (model,))\n",
    "    pool.apply_async(run_kmeans_cube_latent, (model,))\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T11:01:08.328673Z",
     "iopub.status.busy": "2024-01-03T11:01:08.327439Z",
     "iopub.status.idle": "2024-01-03T11:01:08.354865Z",
     "shell.execute_reply": "2024-01-03T11:01:08.353809Z"
    }
   },
   "outputs": [],
   "source": [
    "col_models, col_methods, col_clustering_time, col_stotal_latent, obj_func = [], [], [], [], []\n",
    "\n",
    "for row in rows:\n",
    "    model, method, clustering_time, stotal_latent, silhouette, obj = row\n",
    "\n",
    "    col_models.append(model)\n",
    "    col_methods.append(method)\n",
    "    col_clustering_time.append(clustering_time)\n",
    "    col_stotal_latent.append(stotal_latent)\n",
    "    obj_func.append(obj)\n",
    "\n",
    "col_dict = {'model': col_models, 'method': col_methods,\n",
    "            'clustering time': col_clustering_time, 'silhouette total': col_stotal_latent, 'objective function': obj_func}\n",
    "\n",
    "df = pandas.DataFrame(data=col_dict)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
